# üßô Spamizard - Smart Email Classifier with AI - Powered Reply Assistant
![Accuracy](https://img.shields.io/badge/accuracy-93.04%25-10b981)
![Model](https://img.shields.io/badge/model-Naive%20Bayes%20%2B%20TF--IDF-4f46e5)
![Python](https://img.shields.io/badge/python-3.9%2B-3776AB?logo=python&logoColor=white)
![Flask](https://img.shields.io/badge/flask-2.x-000000?logo=flask)
![License](https://img.shields.io/badge/license-MIT-0ea5e9)

Spamizard is a **production-ready AI email classifier** with a modern web interface, built using **Machine Learning (scikit-learn)** and **Flask**.  
It detects whether an email is **Spam** or **Not Spam** (phishing is mapped to spam) with high accuracy, and can use **Google Gemini API** to generate professional replies for safe emails.

---

## ‚ö†Ô∏è Disclaimer

This project was built as a personal/hackathon demo. It is not a production security product and accuracy is not guaranteed. Misclassifications (false positives/negatives) can and will occur.

- Do not rely on this tool for critical security decisions. Always verify suspicious emails through official channels.
- The software is provided ‚Äúas is,‚Äù without warranty of any kind. The author and contributors are not liable for any loss, damage, or issues arising from its use.
- If you process real data, ensure compliance with your organization‚Äôs privacy/security policies and applicable laws.

---

## ‚ú® Key Features
- üîç **Advanced Spam Detection** using optimized Multinomial Naive Bayes with TF-IDF vectorization
- üõ°Ô∏è **Enhanced Phishing Protection** with obfuscated URL detection and credential harvesting prevention
- üìä **Real-time Confidence Scoring** with probability-based predictions and rule-based overrides
- üéØ **Smart Classification Logic** that reduces false positives on legitimate business emails
- ü§ñ **AI-Powered Email Responses** for legitimate emails via Google Gemini API (toggleable)
- üé® **Modern Responsive Web UI** with dark/light mode, Charizard branding, and accessibility features
- üìÇ **Automated ML Pipeline** with hyperparameter tuning and model validation
- ‚ö° **High Performance** with optimized text preprocessing and feature extraction
- üîí **Production Security** with input validation and error handlingmail Classifier (Spam + Phishing)

---

## üß† Machine Learning Model Details

### **Model Architecture**
- **Algorithm**: Multinomial Naive Bayes Classifier
- **Feature Extraction**: TF-IDF (Term Frequency-Inverse Document Frequency) Vectorization
- **Text Processing**: Advanced NLP pipeline with NLTK integration
- **Optimization**: GridSearchCV for hyperparameter tuning

### **Model Performance**
- **Training Method**: 80/20 train-test split with stratified sampling
- **Cross-Validation**: 5-fold CV with F1-score optimization
- **Data Balancing**: Intelligent upsampling/downsampling for class balance
- **Feature Space**: Up to 5000 features with 1-2 gram analysis

### **Text Preprocessing Pipeline**
1. **Text Normalization**: Lowercase conversion and whitespace handling
2. **Content Cleaning**: URL, HTML tag, and email address removal  
3. **Noise Reduction**: Number and punctuation removal
4. **Stopword Filtering**: NLTK English stopwords removal
5. **Lemmatization**: WordNet-based word normalization
6. **Feature Extraction**: TF-IDF vectorization with n-gram analysis

### **Hyperparameter Optimization**
- **TF-IDF Parameters**:
  - `max_features`: [3000, 5000] - Vocabulary size optimization
  - `ngram_range`: [(1,1), (1,2)] - Unigram vs. bigram analysis
- **Naive Bayes Parameters**:
  - `alpha`: [0.1, 0.3, 0.5, 1.0] - Laplace smoothing optimization
- **Evaluation Metric**: F1-score for balanced precision-recall optimization

---

## üõ†Ô∏è Technology Stack

### **Backend Technologies**
- **Web Framework**: Flask 2.x with Jinja2 templating
- **Machine Learning**: scikit-learn 1.x for model training and inference
- **Data Processing**: pandas, numpy for data manipulation
- **NLP Processing**: NLTK for advanced text preprocessing
- **Model Persistence**: joblib for efficient model serialization
- **Environment Management**: python-dotenv for configuration

### **Frontend Technologies**
- **UI Framework**: Modern HTML5, CSS3 with CSS Grid/Flexbox
- **Styling**: Custom CSS with CSS variables for theming
- **JavaScript**: Vanilla JS for interactive features
- **Typography**: Inter font family for modern aesthetics
- **Accessibility**: ARIA labels, semantic HTML, keyboard navigation

### **AI Integration**
- **Language Model**: Google Gemini 2.0 Flash for response generation
- **API Integration**: google-generativeai SDK
- **Response Quality**: Context-aware prompt engineering

### **Enhanced Spam Detection**
- **Probability Threshold**: Configurable SPAM_THRESHOLD (default: 0.35) for fine-tuned sensitivity
- **Rule-Based Overrides**: Advanced pattern matching with RULES_STRICT mode
- **Phishing Protection**: Detects obfuscated URLs (hxxp://, replace xx with tt patterns)
- **Credential Harvesting Prevention**: Flags SSN, bank account, and password requests
- **Context-Aware Analysis**: Reduces false positives on legitimate HTML invoices and business emails
- **Strong Spam Indicators**: Override system for high-confidence malicious patterns
- **Domain Reputation**: Suspicious TLD detection (.biz, .info, .tk, .ml)
- **Social Engineering Detection**: Urgency + verification request combinations

### **Production & Deployment**
- **WSGI Server**: Gunicorn for production deployment
- **Configuration**: Environment-based config management
- **Security**: Input validation, error handling, secure headers
- **Logging**: Structured logging with configurable levels

---

## üìÇ Project Structure
```
templates/
 ‚îî‚îÄ‚îÄ index.html         # Web UI (dark/light mode, results, response)
 assets/
 ‚îî‚îÄ‚îÄ charizard.png      # Logo
app.py                  # Flask app (loads model, serves predictions)
spam_classifier.py      # ML training pipeline (preprocessing + training + saving models)
spam_dataset.csv        # Original SMS spam/ham dataset (sample)
CEAS_08.csv             # Phishing emails dataset (example)
merge_datasets.py       # Utility to merge datasets (maps phishing‚Üíspam)
spam_phishing_dataset.csv # Merged dataset used for training
spam_model.pkl          # Trained classifier (saved model)
tfidf_vectorizer.pkl    # Saved TF-IDF vectorizer
requirements.txt        # Python dependencies
config.env              # Local environment variables (ignored in Git)
config.env.example      # Example environment config
README.md               # Project documentation
```

---

## ‚öôÔ∏è Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/Aneesh241/spamizard.git
cd spamizard
```

### 2. Create & activate a virtual environment
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Datasets

By default the app trains on `spam_dataset.csv`. To include phishing emails and improve robustness:

- Place your phishing dataset CSV in the project root (e.g., `CEAS_08.csv`).
- Merge datasets (maps phishing ‚Üí spam) to create `spam_phishing_dataset.csv`:

```bash
python merge_datasets.py
# or specify explicit paths
python merge_datasets.py --spam spam_dataset.csv --phish CEAS_08.csv --out spam_phishing_dataset.csv
```

The training script will automatically prefer the merged dataset if present.

### 4. Configure environment variables
Copy the example file and set your own values:
```bash
cp config.env.example config.env
```

Edit `config.env`:
```ini
# API Keys
GOOGLE_API_KEY=your_google_api_key_here

# Spam Detection Configuration
SPAM_THRESHOLD=0.35     # Classification threshold (0.0-1.0, lower = stricter)
RULES_STRICT=true       # Enable enhanced rule-based detection

# Flask Config
SECRET_KEY=your_secret_key_here
FLASK_DEBUG=False
PORT=5000
```

‚ö†Ô∏è **Note:** `config.env` is ignored by Git to protect secrets.

---

## ‚ñ∂Ô∏è Running the Application

```bash
python app.py
```

Flask will start locally on:
```
http://127.0.0.1:5000/
```

Paste an email message into the text area ‚Üí see whether it‚Äôs **Spam** or **Not Spam**.  
If **Not Spam**, the app can also suggest an **AI-generated email reply**.

### Enhanced Spam Detection & AI Responses
- **Smart Toggle**: Use the toggle switch "Generate AI reply when not spam" to enable/disable AI responses
- **Intelligent Classification**: Enhanced phishing detection with obfuscated URL recognition
- **Configurable Sensitivity**: Adjust `SPAM_THRESHOLD` in config.env (lower = stricter detection)
- **Rule-Based Overrides**: Strong spam indicators override ML predictions for better accuracy
- The AI response setting defaults to ON for parity with previous behavior
- If no `GOOGLE_API_KEY` is configured, AI reply generation will be skipped and a notice will be shown

---

## üìä Model Training & Validation

### **Training Process**
To retrain the model with a new dataset:

```bash
python spam_classifier.py
```

### **Training Pipeline Stages**

#### **1. Data Loading & Preprocessing**
- Loads dataset from `spam_phishing_dataset.csv` (merged) if present, otherwise `spam_dataset.csv`
- Normalizes labels (ham/spam ‚Üí 0/1, no/yes ‚Üí 0/1)
- Handles missing values and data type conversion
- Reports initial class distribution

#### **2. Advanced Text Cleaning**
```python
# Text preprocessing steps:
- Lowercase conversion
- URL removal (https://, www.)
- HTML tag stripping
- Email address removal
- Number elimination
- Punctuation removal
- Stopword filtering (NLTK English corpus)
- Lemmatization (WordNet-based)
```

#### **3. Dataset Balancing**
- **Upsampling**: Increases minority class samples
- **Downsampling**: Reduces majority class samples  
- **Strategy**: Maintains statistical significance while ensuring balance
- **Random State**: Fixed seed (42) for reproducible results

#### **4. Model Training & Optimization**
```python
# Pipeline Configuration:
Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
    ('classifier', MultinomialNB())
])

# Hyperparameter Grid:
{
    'tfidf__max_features': [3000, 5000],      # Vocabulary size
    'tfidf__ngram_range': [(1,1), (1,2)],    # N-gram analysis
    'classifier__alpha': [0.1, 0.3, 0.5, 1.0] # Smoothing parameter
}
```

#### **5. Model Evaluation & Validation**
- **Cross-Validation**: 5-fold CV with F1-score optimization
- **Test Split**: 20% holdout with stratified sampling
- **Metrics Reported**:
  - Accuracy score
  - Precision, Recall, F1-score per class
  - Confusion matrix analysis
  - Cross-validation scores with mean and standard deviation

#### **6. Model Persistence**
- **Classifier**: Saved as `spam_model.pkl` (joblib format)
- **Vectorizer**: Saved as `tfidf_vectorizer.pkl` (joblib format)
- **Optimization**: Compressed serialization for faster loading

### **Model Validation Results (Latest Run)**
- Dataset: `spam_phishing_dataset.csv` (merged spam + phishing)
- Size: 43,726 rows (balanced to 21,910 per class before split)
- Best Params: `alpha=1.0`, `tfidf__max_features=5000`, `tfidf__ngram_range=(1,1)`

Results on 20% test split (stratified):

```
Accuracy: 0.9304

Classification Report:
          precision    recall  f1-score   support

        0       0.90      0.97      0.93      4382
        1       0.97      0.89      0.93      4382

   accuracy                           0.93      8764
  macro avg       0.93      0.93      0.93      8764
weighted avg       0.93      0.93      0.93      8764

Confusion Matrix:
[[4269  113]
 [ 497 3885]]

5-Fold CV F1 scores: [0.8533, 0.9307, 0.8985, 0.9115, 0.9285]
Mean CV F1: 0.9045
```

---

## üåê Production Deployment

### **Local Production Server**
```bash
# Using Gunicorn WSGI server
gunicorn app:app --bind 0.0.0.0:8000 --workers 4

# With additional configuration
gunicorn app:app \
  --bind 0.0.0.0:8000 \
  --workers 4 \
  --timeout 120 \
  --max-requests 1000 \
  --log-level info
```

### **Deployment Platforms**

#### **Cloud Platforms**
- **Render**: Direct GitHub integration with automatic builds
- **Railway**: Container-based deployment with scaling
- **Heroku**: Classic PaaS with buildpack support
- **Google Cloud Run**: Serverless container deployment
- **AWS App Runner**: Fully managed container service
- **Azure Container Apps**: Microservices-focused container platform

#### **Containerized Deployment** (Recommended)
```dockerfile
# Dockerfile example
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["gunicorn", "app:app", "--bind", "0.0.0.0:5000"]
```

### **Environment Configuration**
Set these environment variables in production:
```ini
GOOGLE_API_KEY=your_production_api_key
SECRET_KEY=your_secure_secret_key
FLASK_DEBUG=False
PORT=8000
WORKERS=4

# Spam Detection Tuning
SPAM_THRESHOLD=0.35    # Lower = stricter detection (0.0-1.0)
RULES_STRICT=true      # Enable enhanced rule-based overrides
```

### **Performance Optimization**
- **Caching**: Model loaded once at startup
- **Concurrency**: Multi-worker Gunicorn deployment
- **Memory**: Efficient joblib model serialization
- **Response Time**: <200ms average prediction time

---

## üîí Security & Best Practices

### **Environment Security**
- ‚úÖ Never commit `config.env` or API keys to version control
- ‚úÖ Use strong, unique `SECRET_KEY` for session management
- ‚úÖ Rotate Google API keys regularly and monitor usage
- ‚úÖ `.gitignore` configured to exclude sensitive files

### **Application Security**
- **Input Validation**: Email content sanitization and length limits
- **Error Handling**: Graceful error handling without information leakage
- **Logging**: Structured logging without sensitive data exposure
- **Dependencies**: Regular security updates for all dependencies

### **Production Security Checklist**
- [ ] Enable HTTPS with valid SSL certificates
- [ ] Configure proper CORS policies
- [ ] Implement rate limiting for API endpoints
- [ ] Set up monitoring and alerting
- [ ] Regular dependency vulnerability scanning
- [ ] Backup model files and configurations

---

## üìà Model Performance & Metrics

### **Typical Performance Benchmarks**
| Metric | Value | Description |
|--------|-------|-------------|
| **Accuracy** | 95-97% | Overall classification accuracy |
| **Precision (Spam)** | 94-96% | True spam / Predicted spam |
| **Recall (Spam)** | 92-95% | True spam / Actual spam |
| **F1-Score** | 93-95% | Harmonic mean of precision/recall |
| **Prediction Time** | <50ms | Average inference time per email |
| **Model Size** | <10MB | Combined model + vectorizer size |

### **Cross-Validation Results**
- **5-Fold CV Mean F1**: 0.94 ¬± 0.02
- **Consistency**: Low variance across folds
- **Generalization**: Strong performance on unseen data

---

## üöÄ API Usage & Integration

### **Web Interface**
```bash
# Access the web interface
http://localhost:5000/
```

### **Programmatic Usage**
```python
# Example integration
import requests

response = requests.post('http://localhost:5000/', 
    data={'email': 'Your email content here'})
```

### **Response Format**
```json
{
    "result": "Not Spam",
    "confidence_score": 94.5,
    "ai_response": "Generated email reply..."
}
```

---

## üõ†Ô∏è Development & Contributing

### **Setting Up Development Environment**
```bash
# Clone and setup
git clone https://github.com/Aneesh241/spamizard.git
cd spamizard
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### **Running Tests** (Future Enhancement)
```bash
# Unit tests
python -m pytest tests/

# Model validation
python -m pytest tests/test_model.py -v
```

### **Code Quality Tools** (Recommended)
```bash
# Code formatting
black *.py

# Linting
flake8 *.py

# Type checking
mypy *.py
```

---

## üìö Technical Documentation

### **Model Architecture Diagram**
```
Email Input ‚Üí Text Preprocessing ‚Üí TF-IDF Vectorization ‚Üí Naive Bayes ‚Üí Prediction + Confidence
     ‚Üì
Text Cleaning ‚Üí Lemmatization ‚Üí Feature Extraction ‚Üí Classification ‚Üí Response Generation
```

### **Data Flow**
1. **Input**: Raw email text via web form
2. **Preprocessing**: Text cleaning and normalization
3. **Vectorization**: TF-IDF feature extraction
4. **Classification**: Naive Bayes prediction
5. **Post-processing**: Confidence calculation
6. **Response**: Result + AI-generated reply (if not spam)

### **File Structure Details**
```
spamizard/
‚îú‚îÄ‚îÄ app.py                 # Flask web application
‚îú‚îÄ‚îÄ spam_classifier.py     # ML training pipeline  
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ config.env.example     # Environment template
‚îú‚îÄ‚îÄ spam_dataset.csv       # Training dataset
‚îú‚îÄ‚îÄ spam_model.pkl         # Trained classifier
‚îú‚îÄ‚îÄ tfidf_vectorizer.pkl   # Feature extractor
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html         # Web interface
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ charizard.png      # Brand Logo
‚îî‚îÄ‚îÄ .gitignore            # Git ignore rules
```

---

## üöÄ Future Developments

### **Planned Enhancements**
- **üîß Browser Extension**: Transform Spamizard into a Chrome/Firefox extension for real-time email analysis directly within Gmail, Outlook, and other webmail clients
  - Client-side ML model integration for offline processing
  - Seamless integration with popular email providers
  - One-click spam detection without leaving your inbox
- **üì± Mobile App**: Native iOS/Android applications with push notifications
- **ü§ñ Advanced AI Models**: Integration with transformer-based models (BERT, RoBERTa) for improved accuracy
- **üìä Analytics Dashboard**: User analytics with spam trends and detection statistics
- **üîó API Integration**: RESTful API for third-party integrations and enterprise use
- **üåê Multi-language Support**: Spam detection for emails in multiple languages
- **‚ö° Real-time Processing**: WebSocket integration for instant classification
- **üõ°Ô∏è Advanced Security**: Enhanced encryption and privacy protection features
- **üìà Learning Capabilities**: Adaptive model that learns from user feedback

### **Technical Roadmap**
- **Phase 1**: Browser extension development and Chrome Web Store publication
- **Phase 2**: Mobile app development with cross-platform framework
- **Phase 3**: Enterprise API and advanced ML model integration
- **Phase 4**: Multi-language support and global deployment

---

## ÔøΩüìú License
MIT License ‚Äì You are free to use, modify, and distribute this project for educational and commercial purposes.

---

## üë®‚Äçüíª Author & Contact

**Aneesh Sagar Reddy**  
üéì B.Tech CSE (AI & Engineering), Amrita School of Engineering  
üîç Specializing in **Machine Learning, Cybersecurity, and Web Development**

**Connect with me:**
- üìß Email: [Contact via GitHub](https://github.com/Aneesh241)
- üíº LinkedIn: [Professional Profile](https://linkedin.com/in/aneesh241)
- üêô GitHub: [@Aneesh241](https://github.com/Aneesh241)

---

## üôè Acknowledgments
- **scikit-learn** team for the excellent ML library
- **NLTK** project for comprehensive NLP tools
- **Google** for the Gemini API
- **Flask** community for the lightweight web framework
